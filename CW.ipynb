{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farz-1/template/blob/master/CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmPjPj62wgKi",
        "outputId": "d3c12ab0-0c89-4367-abc1-a06b2bc0adb6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/colab/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI2-jKVnxJF2",
        "outputId": "fb4aa639-1ae4-4577-a6d2-d0379e856bda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('tad_data.json') as f:\n",
        "    document = json.load(f)\n"
      ],
      "metadata": {
        "id": "tbEWg2qIxUt5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TvvMTkXwfY1z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dh_tkE4uJWCC",
        "outputId": "fb7d7886-2549-48d3-b5f6-fe3c5b108f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"UID\": \"AVqkIhwDv8e3D1O-lebb\",\n",
            "    \"Name\": \"All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta\",\n",
            "    \"DoRecommend\": \"TRUE\",\n",
            "    \"Rating\": 5,\n",
            "    \"Review\": \"This product so far has not disappointed. My children love to use it and I like the ability to monitor control what content they see with ease.\",\n",
            "    \"Title\": \"Kindle\",\n",
            "    \"Username\": \"Adapter\"\n",
            "  },\n"
          ]
        }
      ],
      "source": [
        "!head tad_data.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szTwg0NRFrco"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siZeH2YoGP1b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oruDcZtzJWCE",
        "outputId": "7327f30b-2d78-48bb-bc1f-3b7dcd466351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This product so far has not disappointed. My children love to use it and I like the ability to monitor control what content they see with ease.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "document[0]['Review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RWg4q6vqJWCE"
      },
      "outputs": [],
      "source": [
        "def column(matrix, i):\n",
        "    return [row[i] for row in matrix]\n",
        "import random\n",
        "\n",
        "data=random.choices(document,k=9900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gZAaTvhCJWCF",
        "outputId": "e68e05d4-9e38-4cf5-9603-4fb251e505f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9900\n",
            "9900\n",
            "198\n",
            "9702\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data[0]\n",
        "\n",
        "vals=[]\n",
        "vals.clear()\n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if(data[i]['DoRecommend']!=\"TRUE\" and data[i]['DoRecommend']!=\"FALSE\"):\n",
        "        vals.append(i)\n",
        "    if(len(data[i]['Review'])<5):\n",
        "        vals.append(i)\n",
        "\n",
        "print(len(data))\n",
        "\n",
        "vals=sorted(vals,reverse=True)\n",
        "\n",
        "print(len(data))\n",
        "for g in vals:\n",
        "  del data[g]\n",
        "print(len(vals))\n",
        "print(len(data))\n",
        "print(type(data[0]['DoRecommend']))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xqs7KJYAJWCF",
        "outputId": "e549d99b-3361-46e0-b849-a005b79429ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5820\n",
            "1941\n",
            "1941\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X= column(data,'DoRecommend')\n",
        "Y= column(data,'Review')\n",
        "\n",
        "rec_train_val,rec_test,rev_train_val,rev_test=train_test_split(X,Y,test_size=0.2, random_state=12)\n",
        "rec_train,rec_val,rev_train,rev_val=train_test_split(rec_train_val,rev_train_val,test_size=0.25,random_state=12)\n",
        "print(len(rec_train))\n",
        "print(len(rec_val))\n",
        "print(len(rec_test))\n",
        "\n",
        "total=len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qnQVbPDGJWCG",
        "outputId": "62d93557-1053-4b80-d069-cbc6fecdd6f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5998763141620285, 0.20006184291898577, 0.20006184291898577)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(rev_train)/total, len(rev_val)/total, len(rev_test)/total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT6IcdcnhfF9",
        "outputId": "8622d03b-9325-4917-d0af-85e40249b45b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vq_T5-IgJWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db1fea4-4e9c-468a-a9b3-d192f9afc5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(rec_train)=5844\tlen(rev_train)=5844\n",
            "len(rec_val)=1948\tlen(rev_val)=1948\n",
            "len(rec_test)=1949\tlen(rev_test)=1949\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(rec_train)=}\\t{len(rev_train)=}\")\n",
        "print(f\"{len(rec_val)=}\\t{len(rev_val)=}\")\n",
        "print(f\"{len(rec_test)=}\\t{len(rev_test)=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7Mvwlj8NJWCH",
        "outputId": "5834204c-3b0f-474f-c542-1cbadea2d6fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged after 56 iterations.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "# Step 0: Vectorizing the text\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "tfidf = vectorizer.fit_transform(rev_train)\n",
        "\n",
        "# Step 1: Picking k random centroids\n",
        "k = 5 # number of clusters\n",
        "samples, features = tfidf.shape\n",
        "centroids = np.zeros((k, features))\n",
        "for i in range(k):\n",
        "    centroid = tfidf[np.random.choice(samples)].toarray()\n",
        "    centroids[i] = centroid\n",
        "\n",
        "# Step 2: Assigning each vector to its closest centroid\n",
        "def assign_cluster(tfidf, centroids):\n",
        "    clusters = []\n",
        "    for i in range(tfidf.shape[0]):\n",
        "        vector = tfidf[i].toarray()\n",
        "        distances = np.linalg.norm(vector - centroids, axis=1)\n",
        "        closest_centroid = np.argmin(distances)\n",
        "        clusters.append(closest_centroid)\n",
        "    return clusters\n",
        "\n",
        "clusters = assign_cluster(tfidf, centroids)\n",
        "\n",
        "# Step 3: Recalculate the centroids based on the closest vectors\n",
        "def recalculate_centroids(tfidf, cluster_assignment, k):\n",
        "    new_centroids = np.zeros((k, features))\n",
        "    for i in range(k):\n",
        "        cluster_mean = np.mean(tfidf[np.where(np.array(clusters) == i)].toarray(), axis=0)\n",
        "        new_centroids[i] = cluster_mean\n",
        "    return new_centroids\n",
        "\n",
        "max_iterations = 100\n",
        "for iteration in range(max_iterations):\n",
        "    clusters = assign_cluster(tfidf, centroids)\n",
        "    new_centroids = recalculate_centroids(tfidf, clusters, k)\n",
        "    if np.allclose(centroids, new_centroids):\n",
        "        break\n",
        "    centroids = new_centroids\n",
        "\n",
        "print(\"Converged after\", iteration + 1, \"iterations.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Get the documents assigned to each cluster and the top 5 tokens with the highest magnitude in the corresponding centroid\n",
        "cluster_assignments = assign_cluster(tfidf, centroids)\n",
        "\n",
        "for i in range(k):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    documents_in_cluster = [rev_train[j] for j in range(len(rev_train)) if cluster_assignments[j] == i]\n",
        "    print(f\"Number of documents in cluster: {len(documents_in_cluster)}\")\n",
        "    centroid = centroids[i]\n",
        "    sorted_idx = np.argsort(centroid)[::-1][:5] # Get the indices of the top 5 tokens with the highest magnitude\n",
        "    top_tokens = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(idx)] for idx in sorted_idx]\n",
        "    print(f\"Top 5 tokens in centroid: {top_tokens}\")\n",
        "    print(\"Example documents in cluster:\")\n",
        "    for j in range(min(5, len(documents_in_cluster))):\n",
        "        print(f\"Document {j+1}: {documents_in_cluster[j]}\")\n",
        "    print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my62kD68z-b5",
        "outputId": "470e8c29-a3bf-45f8-aac5-acf3352afb95"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1:\n",
            "Number of documents in cluster: 2819\n",
            "Top 5 tokens in centroid: ['kindle', 'love', 'bought', 'fire', 'one']\n",
            "Example documents in cluster:\n",
            "Document 1: Many of our questions to her she miss interpreted or replied as not understanding what we were looking for. Distance for her to hear us was minimal. I returned this one and purchased the \"Google\" and this one is much better and more knowledgeable with answers. Both devices recommend using the phone app and also making other purchases for more usage of items that may be available. I didn't expect additional charges and so I'm not to thrilled with either one but I did keep the Google device in hopes of better to come in the future.\n",
            "Document 2: Hard to figure out to use this tablet can't figure out how to close apps. Also says no storage to run wifi. Lastly bought three of them and one is not working wish it came with a user guide\n",
            "Document 3: Comes with a bunch of apps to watch TV and to play games as well.\n",
            "Document 4: We originally owned an original kindle but it was slow app store was not the best and overall interface was to be desired. In fact eventually the device crashed and couldn't be recovered with limited use. Deeply debated about getting another and actually bought a Samsung tablet, but it was too small. This was such a good deal it was hard to ignore and have been very happy to give another try. This device is a great size and much better interface. Would buy again and will consider in the future for the kids.\n",
            "Document 5: Great tablet thats ready right out of the packaging. It comes pre loaded with loads of apps and has a nice feel in the hands. screen quality is nice, the only thing i would like to see changed is the amount of time it takes the kindle to start up and shut down, it can get annoying at times. i have a 2 yo and 8yo and its held up great, dropped on cement and no cracks.\n",
            "----\n",
            "Cluster 2:\n",
            "Number of documents in cluster: 610\n",
            "Top 5 tokens in centroid: ['easy', 'use', 'set', 'great', 'love']\n",
            "Example documents in cluster:\n",
            "Document 1: This thing is awesome. Good volume, blends in with the room and is easy to setup.\n",
            "Document 2: It was a great present for my grandma. It is very easy to use.\n",
            "Document 3: I find this product to be very efficient for several reasons on an everyday use. The more I use it the more I like it\n",
            "Document 4: Bought this for my husband to use for the internet instead of his smartphone. It is simple to use.\n",
            "Document 5: I had put off getting an echo and now, I am hooked on it. It was easy to set up and is extremely easy to use. In conjunction with a harmony remote control and hub, the echo controls the stereo, television and more. The fidelity is surprisingly good for a small unit.\n",
            "----\n",
            "Cluster 3:\n",
            "Number of documents in cluster: 1096\n",
            "Top 5 tokens in centroid: ['tablet', 'price', 'great', 'good', 'kids']\n",
            "Example documents in cluster:\n",
            "Document 1: Chose this tablet due to the parental control features as a gift for my granddaughter.\n",
            "Document 2: Goog tablet the only bad part is that you have to be creating a profile and thats where it gets complicated because when they sell u the tablet they saw its for kids\n",
            "Document 3: It's not the biggest or fastest but for the price it is perfect! It's a great little device that works well.\n",
            "Document 4: LIMITED CAPACITY BUT FOR THE PRICE IT IS A VERY GOOD BUY\n",
            "Document 5: This is the ideal tablet for my 8 year old son ##1\n",
            "----\n",
            "Cluster 4:\n",
            "Number of documents in cluster: 232\n",
            "Top 5 tokens in centroid: ['recommend', 'would', 'product', 'highly', 'anyone']\n",
            "Example documents in cluster:\n",
            "Document 1: This is my first tablet. It is simple to use and very efficient.The only thing that I would have liked would be larger keys on the key pad. Other than that I am very happy with it.\n",
            "Document 2: Wonderful product. Very happy to be cable free! Highly recommend!\n",
            "Document 3: Tons of things you can do with this. Highly recommend it.\n",
            "Document 4: Works for what hubby wanted it for. Will recommend.\n",
            "Document 5: Works as annticapated. Would recommend. Might buy another one. This survey is not working right.???????????\n",
            "----\n",
            "Cluster 5:\n",
            "Number of documents in cluster: 1087\n",
            "Top 5 tokens in centroid: ['great', 'echo', 'alexa', 'music', 'product']\n",
            "Example documents in cluster:\n",
            "Document 1: Great purchase and good investment.Also wonderful viewing\n",
            "Document 2: Sound quality is pretty good if you want it to play background music, but I still prefer Sonos for this purpose. Alexa is useful for controlling the widest range of smart home products, but it's not backed by Google Home's superior search intelligence, so it isn't that great for asking in-depth questions of it. There are comparisons of these products out there, so take a look before making a decision. Since I mostly wanted it for home control, it suits my need.\n",
            "Document 3: This is great toy. You may not need it, but you'll want it, and love it when you start using it.\n",
            "Document 4: She's smart, funny, entertaining and very helpful. You should have her in your home. She's so worth it!\n",
            "Document 5: My kids really enjoy the alexa. I will buy more of these in the future\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzhgJ_pYhdfq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mHTJq2RwJWCI",
        "outputId": "6e479a51-4a49-4fc9-a1c7-7d1b9608a35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD5CAYAAADSiMnIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYvklEQVR4nO3dX2xc533m8e8jqiax3TKVbNY1JCuULQmWDSwcZKISu2jq1qSlLFaSgbqo0jRmW8uq1Bh7ERSQC7cIoOxF2FwUufBKlpTWSoFAdlygpQI0BOnYRXtBV6PUtSPHkmhFjiU4iWo5YbYJTYj87cU5Ew2HcyQO58wfUs8HIHj+vO+Zn4bkPJrzznuOIgIzM7NqVrS6ADMza18OCTMzy+SQMDOzTA4JMzPL5JAwM7NMDgkzM8u0Mo+DSNoGfAnoAI5GxBcq9n8W2A1cBS4DfxQRb6f7BoE/T5v+n4g4dqPHu+2226K3tzeP0s3MbhqnTp36j4joqaWP6p0nIakDOAsMABeBk8AnI+KNsja/CbwSET+VtA94ICJ+V9JqoAgUgABOAR+NiPev95iFQiGKxeLCCpyZgRUrQJq/b3YWIqCjY2HHMjNbwiSdiohCLX3yON20BZiIiPMRMQ0cB3aWN4iIlyLip+nqOLA2Xd4KjEbElTQYRoFtOdSUGBuDu++Ge+6B8fG5+8bHYfNm2LAhaWdmZvPkERJrgHfK1i+m27I8BvzjIvsu3OgobN8Ob78NZ8/C1q3XgmJ8PFk/exYuXEjajY7m8rBmZstJUweuJf0+yamlLy6i7x5JRUnFy5cvX7/x6Cjs2AFTU9e2TU4mwXDoUPJ9cvLavqmppL2DwsxsjjxC4hJwZ9n62nTbHJL6gaeAHRHxQS19ASLicEQUIqLQ03OdcZexsfkBUTI5Cfv2zQ2IklJQ+NSTmdnP5RESJ4GNktZLugXYBQyXN5D0EeAZkoD4YdmuEeAhSaskrQIeSrctzswM7N5dPSAWYmoKHn88OY6ZmdX/EdiIuCrpCZIX9w7gryPitKQDQDEihklOL/1X4GtKPmX0vYjYERFXJH2eJGgADkTElUUXI0FnZz3/nKT/Ck8fMTODHD4C2wrX/QhsaVC62imlG+nuhpER6Ourr0AzszbUqo/Atpe+vuSFvru7tn4OCDOzeZZfSEDyQj80VFufoSEHhJlZheUZEuPjsH9/bX32758/4c7M7Ca3/EJisWMSpXkUDgozs59bXiExOwuPPrq4QWtI+g0OJtdzMjOzZRYSETA9Xd8xpqeTsDEzs2UWEh0dcPQodHUtrn9XFxw54qvCmpmllldIAPT3w/Bw9aDo7oaDB6t/PLarK+nX39/4Gs3MlojlFxIAAwPzg6I0D2Lv3vnzKEoBMTDQ/FrNzNrY8gwJSF7wT5yA3l7YtGnuRLnShLtNm5L9J044IMzMqsjl9qVtq78fJiaq35murw/efDMZpPYYhJlZVcs7JOD6ASA5IMzMrmP5nm4yM7O6OSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwy5RISkrZJOiNpQtKTVfZ/XNK3JF2V9EjFvhlJr6Zfw3nUY2Zm+aj7UuGSOoCngQHgInBS0nBEvFHW7HvAHwB/WuUQP4uI++utw8zM8pfH/SS2ABMRcR5A0nFgJ/DzkIiIC+m+2Rwez8zMmiSP001rgHfK1i+m2xaqS1JR0rikh3Oox8zMctIOd6b7cERcknQX8E1Jr0fEW5WNJO0B9gCsW7eu2TWamd2U8ngncQm4s2x9bbptQSLiUvr9PPAy8JGMdocjohARhZ6ensVXa2ZmC5ZHSJwENkpaL+kWYBewoE8pSVolqTNdvg34H5SNZZiZWWvVHRIRcRV4AhgBvgM8HxGnJR2QtANA0sckXQR+B3hG0um0+2agKOnfgZeAL1R8KsrMzFpIEdHqGmpWKBSiWCy2ugwzsyVF0qmIKNTSxzOuzcwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsUy4hIWmbpDOSJiQ9WWX/xyV9S9JVSY9U7BuUdC79GsyjHjMzy0fdISGpA3ga+ARwL/BJSfdWNPse8AfAVyv6rgY+B/wasAX4nKRV9dZkZmb5yOOdxBZgIiLOR8Q0cBzYWd4gIi5ExGvAbEXfrcBoRFyJiPeBUWBbDjWZmVkO8giJNcA7ZesX022N7mtmZg22ZAauJe2RVJRUvHz5cqvLMTO7KeQREpeAO8vW16bbcu0bEYcjohARhZ6enkUVamZmtckjJE4CGyWtl3QLsAsYXmDfEeAhSavSAeuH0m1mZtYG6g6JiLgKPEHy4v4d4PmIOC3pgKQdAJI+Juki8DvAM5JOp32vAJ8nCZqTwIF0m5mZtQFFRKtrqFmhUIhisdjqMszMlhRJpyKiUEufJTNwbWZmzeeQMDOzTA4JMzPL5JAwM7NMDgkzM8vkkDAzs0wOCTMzy+SQMDOzTA4JMzPL5JAwM7NMDgkzM8vkkDAzs0wOCTMzy+SQMDOzTA4JMzPL5JAwM7NMDgkzM8vkkDAzs0wOCTMzy+SQMDOzTA4JMzPL5JAwM7NMDgkzM8vkkDAzs0wOCTMzy5RLSEjaJumMpAlJT1bZ3ynpuXT/K5J60+29kn4m6dX061Ae9ZiZWT5W1nsASR3A08AAcBE4KWk4It4oa/YY8H5EbJC0CxgCfjfd91ZE3F9vHWZmlr883klsASYi4nxETAPHgZ0VbXYCx9LlF4AHJSmHxzYzswbKIyTWAO+UrV9Mt1VtExFXgR8Dt6b71kv6N0n/JOnXc6jHzMxyUvfppjq9C6yLiPckfRT4e0n3RcRkZUNJe4A9AOvWrWtymWZmN6c83klcAu4sW1+bbqvaRtJK4EPAexHxQUS8BxARp4C3gE3VHiQiDkdEISIKPT09OZRtZmY3kkdInAQ2Slov6RZgFzBc0WYYGEyXHwG+GREhqScd+EbSXcBG4HwONZmZLX0zMxBRfd/sbLK/weoOiXSM4QlgBPgO8HxEnJZ0QNKOtNmXgVslTQCfBUofk/048JqkV0kGtPdGxJV6azIzW/LGxuDuu+Gee2B8fO6+8XHYvBk2bEjaNZAiK6XaWKFQiGKx2OoyzMwaY3QUduyAqalkvbsbRkagry8JiK1bYTIduu3qguFhGBi44WElnYqIQi2leMa1mVk7qQwISAJh61Y4dGhuQEDSbseOpF8DOCTMzNrF2Nj8gCiZnIR9++YGREkpKBpw6skhYWbWDmZmYPfu6gGxEFNT8PjjuQ9mOyTMzNqBBJ2d9R2jsxNW5Puy7pAwM2sHK1bAsWPJIPVidHfDs88mYZNnWbkezczMFq+vL/kUU61BUf7pp5w5JMzM2klfHwwN1dZnaKghAQEOCTOz9jI+Dvv319Zn//75E+5y4pAwM2sXlRPlFqo0j6IBQeGQMDNrB7Oz8OijtQdEyeQkDA5mX+tpkRwSZmbtIAKmp+s7xvR0EjY5ckiYmbWDjg44ejS5FtNidHXBkSPJcXLkkDAzaxf9/cnF+qoFRXc3HDxY/eOxpYv89ffnXpJDwsysnQwMzA+K0jyIvXvnz6Oo4Sqwi+GQMDNrNwMDcOIE9PbCpk1zJ8qVJtxt2pTsP3GiYQEBrb/HtZmZVdPfDxMTyeU6Ki+10dcHb76ZDFLnPAZRySFhZtaurhcAUsMDAny6yczMrsMhYWZmmRwSZmaWySFhZmaZHBJmZpbJIWFmZpkcEmZmlskhYWZmmXIJCUnbJJ2RNCHpySr7OyU9l+5/RVJv2b4/S7efkbQ1j3rMzCwfdYeEpA7gaeATwL3AJyXdW9HsMeD9iNgA/BUwlPa9F9gF3AdsA/5vejwzM2sDebyT2AJMRMT5iJgGjgM7K9rsBI6lyy8AD0pSuv14RHwQEd8FJtLjmZlZG8gjJNYA75StX0y3VW0TEVeBHwO3LrCvmZm1yJIZuJa0R1JRUvHy5cutLsfM7KaQR0hcAu4sW1+bbqvaRtJK4EPAewvsC0BEHI6IQkQUenp6cijbzMxuJI+QOAlslLRe0i0kA9HDFW2GgcF0+RHgmxER6fZd6aef1gMbgX/NoSYzM8tB3feTiIirkp4ARoAO4K8j4rSkA0AxIoaBLwN/K2kCuEISJKTtngfeAK4Cn4mImXprMjOzfCj5D/3SUigUolgstroMM7MlRdKpiCjU0mfJDFybmVnzOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0Oi3c3MQET1fbOzyX4zswapKyQkrZY0Kulc+n1VRrvBtM05SYNl21+WdEbSq+nXr9RTz7IzNgZ33w333APj43P3jY/D5s2wYUPSzsysAep9J/Ek8GJEbAReTNfnkLQa+Bzwa8AW4HMVYfKpiLg//fphnfUsH6OjsH07vP02nD0LW7deC4rx8WT97Fm4cCFpNzra0nLNbHmqNyR2AsfS5WPAw1XabAVGI+JKRLwPjALb6nzc5W10FHbsgKmpa9smJ5NgOHQo+T45eW3f1FTS3kFhZjmrNyRuj4h30+XvA7dXabMGeKds/WK6reRv0lNNfyFJddaz9I2NzQ+IkslJ2LdvbkCUlILCp57MLEcrb9RA0hjwq1V2PVW+EhEhKWOENdOnIuKSpF8C/g74NPCVjDr2AHsA1q1bV+PDLBEzM7B7d/WAWIipKXj8cZiYgI6OfGszs5vSDUMiIvqz9kn6gaQ7IuJdSXcA1cYULgEPlK2vBV5Oj30p/f4TSV8lGbOoGhIRcRg4DFAoFGoNo6VBgs7O+o7R2Qkr/KE1M8tHva8mw0Dp00qDwD9UaTMCPCRpVTpg/RAwImmlpNsAJP0C8L+Ab9dZz9K2YgUcOwbd3Yvr390Nzz6bhI2ZWQ7qDYkvAAOSzgH96TqSCpKOAkTEFeDzwMn060C6rZMkLF4DXiV5x3GkznqWvr4+GBmpPSi6u5N+fX2NqcvMbkqKrIlabaxQKESxWGx1GY116FAySL1QBw/C3r3X1mdnk0l4Hpsws5SkUxFRqKWPT163o/Fx2L+/tj7798+dR+GJdmaWA4dEuylNlKv2MdfrKc2jOHrUE+3MLDcOiXYyOwuPPlp7QJRMTsIf/7En2plZbhwS7SQCpqfrO8bs7PxtnmhnZovkkGgnHR3J6aKurvyPXZpo56vGmlkNHBLtpr8fhoerB0W9k+Q80c7MauRXjHY0MDA/KLq74ZlnPNHOzJrKIdGuBgbgxAno7YVNm5KJcrt3e6KdmTWVQ6Kd9fcnF+t7881rL/B9fTA0VNtxhoYcEGa2KA6JdtfRMfcUUb0T7czMauCQWErqnWjnoDCzGjkkloo8JtoNDiZzMczMFsghsVTkMdFuerr6ZDszswwOiaWi3ol2XV1w5IivCmtmNXFILCXXm2jX3Z1cLrzax2O7upJ+/Zk3GTQzq8ohsdRkTbQbGUnuJ1E5j6IUEAMDza/VzJY8h8RSVG2iXfk8ipGRZHtvb9LOAWFmi7Sy1QXYIpUm2q1YMf9SG319yQS82VmPQZhZXRwSS9n1AkByQJhZ3Xy6yczMMjkkWm1mJnuC2+ys7/9gZi3lkGilsTG4+2645575l8wYH4fNm2HDBt9RzsxaxiHRKqOjsH07vP02nD0799pKpWs0nT0LFy4k7XyPajNrAYdEK4yOJvecnpq6tq10Eb5Dh+ZfxK90j2oHhZk1mUOi2cbG5gdEyeQk7NtX/SJ+paDwqScza6K6QkLSakmjks6l31dltPuGpB9J+nrF9vWSXpE0Iek5SbfUU0/bm5lJ7i5XLSAWYmoKHn/cg9lm1jT1vpN4EngxIjYCL6br1XwR+HSV7UPAX0XEBuB94LE662lvEnR21neMzs5kAp2ZWRPU+2qzEziWLh8DHq7WKCJeBH5Svk2SgN8CXrhR/2VjxQo4dqz2e1SXdHfDs8/On2FtZtYg9YbE7RHxbrr8feD2GvreCvwoIq6m6xeBNXXW0/5K11aqNShKF/HzvarNrIluGBKSxiR9u8rXzvJ2ERFAw257JmmPpKKk4uXLlxv1MM3R1wdDQ7X1GRpyQJhZ093w2k0RkXkTAkk/kHRHRLwr6Q7ghzU89nvAL0tamb6bWAtcuk4dh4HDAIVCYWnfg3N8HPbvr63P/v1w//0OCjNrqnpPNw0Dg+nyIPAPC+2YvvN4CXhkMf2XrNJEuVrvVV2aR1E5M9vMrIHqDYkvAAOSzgH96TqSCpKOlhpJ+mfga8CDki5K2pru2g98VtIEyRjFl+usp73NzsKjj9YeECWTkzA4mH2tJzOznNV1qfCIeA94sMr2IrC7bP3XM/qfB7bUU8OSEgHT0/UdY3ra94kws6bxB+6bqaMDjh6tfo/qhejqgiNHHBBm1jQOiWbr759/j+qS7m44eLD6x2NL96ruz/wcgZlZ7hwSrTAwMD8oSvMg9u6dP4+iFBC+V7WZNZlDolUGBuDECejthU2b5k6UK02427Qp2X/ihAPCzFrC97hupf5+mJhILtdReamNvj54800PUptZSymW4McpJV0G3m7yw94G/EeTH3Mh2rGudqwJXFct2rEmcF21qqzrwxHRU8sBlmRItIKkYkQUWl1HpXasqx1rAtdVi3asCVxXrfKoy2MSZmaWySFhZmaZHBILd7jVBWRox7rasSZwXbVox5rAddWq7ro8JmFmZpn8TsLMzDI5JMpIWi1pVNK59PuqjHbfkPQjSV+v2L5e0iuSJiQ9J+mWJtY0mLY5J2mwbPvLks5IejX9+pU669mWHm9C0rx7mkvqTP/tE+lz0Vu278/S7WfKrgSci8XWJalX0s/Knp9DTazp45K+JemqpEcq9lX9ebZBXTNlz9Vwk+v6rKQ3JL0m6UVJHy7b15Dnq86aWvlc7ZX0evrY/yLp3rJ9tf0dRoS/0i/gL4En0+UngaGMdg8C24GvV2x/HtiVLh8C9jWjJmA1cD79vipdXpXuexko5PT8dABvAXcBtwD/Dtxb0eZPgEPp8i7guXT53rR9J7A+PU5HG9TVC3y7Ab9LC6mpF/hvwFeARxby82xlXem+/5f3c1VDXb8J/Jd0eV/Zz7Ahz1c9NbXBc9VdtrwD+Ea6XPPfod9JzLUTOJYuHwMertYoIl4EflK+TZKA3wJeuFH/BtS0FRiNiCsR8T4wCmzL4bErbQEmIuJ8REwDx9P6sup9geQeIkq3H4+IDyLiu8AE+V0mvp66GuWGNUXEhYh4DZit6NvIn2c9dTXSQup6KSJ+mq6Ok9zNEhr3fNVTUyMtpK7ym9b8ItduLV3z36FDYq7bI+LddPn7wO019L0V+FEkt2IFuAisaVJNa4B3ytYrH/tv0redf1HnC+ONHmdOm/S5+DHJc7OQvq2oC2C9pH+T9E+Sqt77pEE1NaJvo4/dpeRe8+OSHs6ppsXU9Rjwj4vs24yaoMXPlaTPSHqL5GzE/66lb7mb7tpNksaAX62y66nylYgISU356FeDa/pURFyS9EvA3wGfJjmNYIl3gXUR8Z6kjwJ/L+m+iv+J2TUfTn+f7gK+Ken1iHirmQVI+n2gAPxGMx/3ejJqaulzFRFPA09L+j3gz7l2q+ma3HQhERGZN2SQ9ANJd0TEu5LuAH5Yw6HfA35Z0sr0f6prgUtNqukS8EDZ+lqSsQgi4lL6/SeSvkry1nKxIXEJuLPicSr/jaU2FyWtBD5E8twspO9iLbquSE7UfgAQEafS/3ltAopNqOl6fR+o6PtynfWUH3vRP4ey36fzkl4GPkJyXrspdUnqJ/nP029ExAdlfR+o6Ptyi2tq+XNV5jhwcJF9PXBd/gV8kbmDxH95nbYPMH/g+mvMHbj+k2bURDJg912SQbtV6fJqkv8E3Ja2+QWSc/F766hlJcmg4HquDZjdV9HmM8wdIH4+Xb6PuQNm58lv4LqeunpKdZAMBF4CVjejprK2zzJ/4Hrez7NZz9V16loFdKbLtwHnqBgwbfDPsPQiu3Ehv/8trqnVz9XGsuXtQDFdrvnvsO6Cl9MXyTnqF9Mf6FjpF43kbeTRsnb/DFwGfkZyTm9ruv0u4F9JBoO+VvolaVJNf5Q+7gTwh+m2XwROAa8Bp4Ev3egXYgH1/E/gbPqH8VS67QCwI13uSv/tE+lzcVdZ36fSfmeAT+T8s1tUXcBvp8/Nq8C3gO1NrOlj6e/Pf5K82zp9vZ9nq+sC/jvwevoi8zrwWJPrGgN+kP6sXgWGG/18LbamNniuvlT2e/0SZSFS69+hZ1ybmVkmf7rJzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCzT/wdmgcfrNfh+tQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "centroids_2d = pca.fit_transform(centroids)\n",
        "plt.scatter(centroids_2d[:,0], centroids_2d[:,1], marker='X', s=200, linewidths=3, color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# Print the sizes of each set\n",
        "print(\"Number of training examples:\", len(train_data))\n",
        "print(\"Number of validation examples:\", len(val_data))\n",
        "print(\"Number of test examples:\", len(test_data))"
      ],
      "metadata": {
        "id": "UFiSlM9B_gNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c615e7d-ce53-4e49-a775-950acc9b0398"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 5844\n",
            "Number of validation examples: 1948\n",
            "Number of test examples: 1949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "\n",
        "rec_train_val, rec_test, rev_train_val, rev_test = train_test_split(\n",
        "    [d['DoRecommend'] + ' ' + d['Review'] for d in data],\n",
        "    [d['Review'] for d in data],\n",
        "    test_size=0.2, random_state=12)\n",
        "rec_train, rec_val, rev_train, rev_val = train_test_split(\n",
        "    rec_train_val, rev_train_val,\n",
        "    test_size=0.25, random_state=12)\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "tfidf = vectorizer.fit_transform(rev_train_val)\n",
        "\n",
        "# Define the number of clusters\n",
        "k = 5\n",
        "\n",
        "# Initialize the centroids\n",
        "samples, features = tfidf.shape\n",
        "centroids = np.zeros((k, features))\n",
        "for i in range(k):\n",
        "    centroid = tfidf[np.random.choice(samples)].toarray()\n",
        "    centroids[i] = centroid\n",
        "\n",
        "# Define the maximum number of iterations\n",
        "max_iterations = 100\n",
        "\n",
        "# Iterate until convergence\n",
        "for iteration in range(max_iterations):\n",
        "    # Assign each vector to its closest centroid\n",
        "    clusters = []\n",
        "    for i in range(tfidf.shape[0]):\n",
        "        vector = tfidf[i].toarray()\n",
        "        distances = np.linalg.norm(vector - centroids, axis=1)\n",
        "        closest_centroid = np.argmin(distances)\n",
        "        clusters.append(closest_centroid)\n",
        "\n",
        "    # Recalculate the centroids based on the closest vectors\n",
        "    new_centroids = np.zeros((k, features))\n",
        "    for i in range(k):\n",
        "        cluster_mean = np.mean(tfidf[np.where(np.array(clusters) == i)].toarray(), axis=0)\n",
        "        new_centroids[i] = cluster_mean\n",
        "\n",
        "    # Check for convergence\n",
        "    if np.allclose(centroids, new_centroids):\n",
        "        break\n",
        "\n",
        "    centroids = new_centroids\n",
        "\n",
        "print(\"Converged after\", iteration + 1, \"iterations.\")"
      ],
      "metadata": {
        "id": "mgcZTgmeVnjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eebc085-c7a6-454a-8dfb-229db6ba6397"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged after 22 iterations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rec_train_val[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VXT5Nlbmkj03",
        "outputId": "141bcee9-3321-4ec2-bf2f-53590fc57aff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TRUE This is a good product and streams very well for all of our favorite online services!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign each vector to its closest centroid\n",
        "clusters = []\n",
        "for i in range(tfidf.shape[0]):\n",
        "    vector = tfidf[i].toarray()\n",
        "    distances = np.linalg.norm(vector - centroids, axis=1)\n",
        "    closest_centroid = np.argmin(distances)\n",
        "    clusters.append(closest_centroid)\n",
        "# Define a function to print the top tokens in each cluster\n",
        "def print_top_tokens_in_cluster(cluster_idx, centroid, vectorizer, n_tokens=5):\n",
        "    top_indices = centroid.argsort()[::-1][:n_tokens]\n",
        "    top_tokens = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(index)] for index in top_indices]\n",
        "    print(\"Cluster\", cluster_idx)\n",
        "    print(\"Top tokens:\", top_tokens)\n",
        "    print()\n",
        "\n",
        "# Print the first few documents assigned to each cluster and their top tokens\n",
        "num_docs_to_print = 5\n",
        "for i in range(k):\n",
        "    cluster_indices = np.where(np.array(clusters) == i)[0]\n",
        "    print(\"Documents assigned to cluster\", i+1, \":\")\n",
        "    for j, idx in enumerate(cluster_indices):\n",
        "        if j >= num_docs_to_print:\n",
        "            break\n",
        "        print(rev_train_val[idx])\n",
        "    print()\n",
        "    print_top_tokens_in_cluster(i, centroids[i], vectorizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4toxkhAYY6C",
        "outputId": "2ae60b70-e7c9-4682-f3d5-58e957b5c158"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents assigned to cluster 1 :\n",
            "Bought two...one for each kid for Christmas. Perfect for the kids. Download their shows and music. Keeps them off ours. Durable enough for them to use on their own.\n",
            "I have used this everynight since I bought it to catch all my favorite shows and movies. I am so glad I bought this product!!!!!!\n",
            "Bought this tablet for my 2 &1/2 year old and it is perfect. Games and videos that come on it are very age appropriate and the tablet has been very durable thus far.\n",
            "We bought this as a birthday present for my 8 year old. It has almost everything she wants on it. Only problem is Amazon's app options are limited compared to Apple or Google Play. Other than that, she loves it.\n",
            "My children loved their previous kindles so much I bought them an upgrade with the case - so worth it.\n",
            "\n",
            "Cluster 0\n",
            "Top tokens: ['loves', 'bought', 'gift', 'old', 'year']\n",
            "\n",
            "Documents assigned to cluster 2 :\n",
            "This is a good product and streams very well for all of our favorite online services!\n",
            "Sound quality is pretty good if you want it to play background music, but I still prefer Sonos for this purpose. Alexa is useful for controlling the widest range of smart home products, but it's not backed by Google Home's superior search intelligence, so it isn't that great for asking in-depth questions of it. There are comparisons of these products out there, so take a look before making a decision. Since I mostly wanted it for home control, it suits my need.\n",
            "Simple to operate for a 3 yr old . Would recommend\n",
            "was skeptical at first because I thought it would be the same as the fire stick.Boy was I wrong.4k is awesome on my 4k tetevision.\n",
            "Very power full box, great for streaming 4K look beautiful.\n",
            "\n",
            "Cluster 1\n",
            "Top tokens: ['amazon', 'tv', 'love', 'echo', 'alexa']\n",
            "\n",
            "Documents assigned to cluster 3 :\n",
            "The voyage is so much easier on the eyes. The size is great and easy to carry in a briefcase for travel purposes.\n",
            "I purchased this tablet for my grandchildren over the holidays. they are 3 and 6yrs old. they love it . it's easy to use - and they are able to scroll through the programs easily.\n",
            "Love the silver color and larger screen also easy to navigate\n",
            "Long battery life, clear,crisp screen,lightweight and easy to hold. Compatible with Amazon's vast ecosystem of reading materials. Lose yourself in the book--- it is a joy to use.\n",
            "Easy to access the apps, but not always easy to quit. The device works good, but since it's the apps that make it what it is, more attention should be given to their operation. I was disappointed that it did not come with even a basic user's guide.\n",
            "\n",
            "Cluster 2\n",
            "Top tokens: ['easy', 'use', 'great', 'set', 'love']\n",
            "\n",
            "Documents assigned to cluster 4 :\n",
            "The Kindle works as it should and was inexpensive but has a short battery life\n",
            "My daughter love her new tablet, I use for a few days and it's pretty good\n",
            "love the worry free guarantee since this has been dropped several times. with that being said this tablet hs held up\n",
            "This tablet is hands down the best investment I've ever made. I used to carry a laptop to meetings, then my kids talked me into getting a tablet and what a difference. As long as there is wifi it does everything my laptop will.\n",
            "I wore out my first generation paperwhite......onto the next! Kindle paperwhites are the way to go!\n",
            "\n",
            "Cluster 3\n",
            "Top tokens: ['tablet', 'kindle', 'good', 'reading', 'read']\n",
            "\n",
            "Documents assigned to cluster 5 :\n",
            "Excellent product very good piece strongly recommend\n",
            "Brought it for my toddler for xmas, so hopefully it works great.\n",
            "This tablet was a gift for my nephew who is 10, great gift where he can use it to get on the internet. It works well for what he is using it for.\n",
            "Very versatile and can be great for kids & adults.\n",
            "Great product & price, especially for gift giving (especially for children).\n",
            "\n",
            "Cluster 4\n",
            "Top tokens: ['great', 'product', 'price', 'works', 'tablet']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "centroids_2d = pca.fit_transform(centroids)\n",
        "plt.scatter(centroids_2d[:,0], centroids_2d[:,1], marker='X', s=200, linewidths=3, color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6KmhHlPklbEv",
        "outputId": "8cf9c9e1-17f8-4f5a-a9ae-d77baaa824ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "# ...\n",
        "\n",
        "# Create a dummy classifier with strategy 'most_frequent'\n",
        "dummy_clf = DummyClassifier(strategy='stratified')\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dummy_clf.fit(rec_train, rev_train)\n",
        "\n",
        "# Predict on the validation data\n",
        "y_pred = dummy_clf.predict(rec_val)\n",
        "\n",
        "# Calculate accuracy on the validation data\n",
        "accuracy = dummy_clf.score(rec_val, rev_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "PpQFFfD91tGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffbf35d-8fb6-40ab-ef27-797c43367e30"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Convert text data to a matrix of word counts\n",
        "vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "X_text = vectorizer.fit_transform(rev_train_val)\n",
        "\n",
        "# Convert the word count matrix to a binary matrix of one-hot vectors\n",
        "encoder = OneHotEncoder()\n",
        "X_one_hot = encoder.fit_transform(X_text.toarray())\n",
        "\n",
        "# Convert the sparse matrix to a dense numpy array\n",
        "X_one_hot_dense = X_one_hot.toarray()\n",
        "\n",
        "# Concatenate the one-hot matrix with the binary DoRecommend feature\n",
        "X = np.concatenate([X_one_hot_dense, np.array(rec_train_val).reshape(-1, 1)], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, rec_train_val, test_size=0.2, random_state=12)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=12)\n",
        "\n",
        "# Fit the LogisticRegression model to the training data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation and testing sets\n",
        "print(\"Validation accuracy:\", model.score(X_val, y_val))\n",
        "print(\"Testing accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "OiT49wYn3WU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkOGzSS04mDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHQnOjlSizzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    [d['DoRecommend'] + ' ' + d['Review'] for d in data],\n",
        "    [d['DoRecommend'] for d in data],\n",
        "    test_size=0.2, random_state=12)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val,\n",
        "    test_size=0.25, random_state=12)\n",
        "\n",
        "dummy_classifiers = [\n",
        "    DummyClassifier(strategy=\"most_frequent\"),\n",
        "    DummyClassifier(strategy=\"stratified\")\n",
        "]\n",
        "logistic_regression = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "svc = SVC(kernel='rbf')\n",
        "\n",
        "# Define the feature representations\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Evaluate the classifiers using cross-validation\n",
        "for clf in dummy_classifiers + [logistic_regression, svc]:\n",
        "    for vectorizer in [count_vectorizer, tfidf_vectorizer]:\n",
        "        X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "        scores = cross_val_score(clf, X_train_transformed, y_train, cv=5)\n",
        "        print(f\"{clf.__class__.__name__} with {vectorizer.__class__.__name__}: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
        "print('*'*50)\n",
        "# Evaluate the classifiers using cross-validation\n",
        "results = []\n",
        "for clf in dummy_classifiers + [logistic_regression, svc]:\n",
        "    for vectorizer in [count_vectorizer, tfidf_vectorizer]:\n",
        "        X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "        X_val_transformed = vectorizer.transform(X_val)\n",
        "        clf.fit(X_train_transformed, y_train)\n",
        "        y_pred = clf.predict(X_val_transformed)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        precision = precision_score(y_val, y_pred, average='macro',zero_division=0)\n",
        "        recall = recall_score(y_val, y_pred, average='macro')\n",
        "        f1 = f1_score(y_val, y_pred, average='macro')\n",
        "        result = {'Classifier': clf.__class__.__name__,\n",
        "                  'Vectorizer': vectorizer.__class__.__name__,\n",
        "                  'Accuracy': accuracy,\n",
        "                  'Precision': precision,\n",
        "                  'Recall': recall,\n",
        "                  'F1': f1}\n",
        "        results.append(result)\n",
        "\n",
        "# Print the results\n",
        "print('{:<25} {:<20} {:<10} {:<10} {:<10} {:<10}'.format(\n",
        "    'Classifier', 'Vectorizer', 'Accuracy', 'Precision', 'Recall', 'F1'))\n",
        "best_f1 = 0\n",
        "for result in results:\n",
        "    classifier = result['Classifier']\n",
        "    vectorizer = result['Vectorizer']\n",
        "    accuracy = result['Accuracy']\n",
        "    precision = result['Precision']\n",
        "    recall = result['Recall']\n",
        "    f1 = result['F1']\n",
        "    print('{:<25} {:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(\n",
        "        classifier, vectorizer, accuracy, precision, recall, f1))\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_classifier = classifier\n",
        "        best_vectorizer = vectorizer\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff9naNWbkqi8",
        "outputId": "a844217f-af91-49b2-ad8d-d2b36f89b577"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier with CountVectorizer: 0.957 +/- 0.000\n",
            "DummyClassifier with TfidfVectorizer: 0.957 +/- 0.000\n",
            "DummyClassifier with CountVectorizer: 0.917 +/- 0.005\n",
            "DummyClassifier with TfidfVectorizer: 0.919 +/- 0.004\n",
            "LogisticRegression with CountVectorizer: 1.000 +/- 0.000\n",
            "LogisticRegression with TfidfVectorizer: 0.973 +/- 0.001\n",
            "SVC with CountVectorizer: 0.988 +/- 0.002\n",
            "SVC with TfidfVectorizer: 0.987 +/- 0.003\n",
            "**************************************************\n",
            "Classifier                Vectorizer           Accuracy   Precision  Recall     F1        \n",
            "DummyClassifier           CountVectorizer      0.962      0.481      0.500      0.490     \n",
            "DummyClassifier           TfidfVectorizer      0.962      0.481      0.500      0.490     \n",
            "DummyClassifier           CountVectorizer      0.929      0.496      0.496      0.496     \n",
            "DummyClassifier           TfidfVectorizer      0.927      0.519      0.521      0.520     \n",
            "LogisticRegression        CountVectorizer      1.000      1.000      1.000      1.000     \n",
            "LogisticRegression        TfidfVectorizer      0.979      0.990      0.726      0.806     \n",
            "SVC                       CountVectorizer      0.992      0.996      0.890      0.936     \n",
            "SVC                       TfidfVectorizer      0.993      0.996      0.904      0.945     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing Classifiers \n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "#Define the training and validation sets:\n",
        "X_train, X_val, y_train, y_val = train_test_split(rev_train_val, rec_train_val, test_size=0.2, random_state=12)\n",
        "\n",
        "#Define the classifiers and their parameters:\n",
        "dummy_classifiers = [    DummyClassifier(strategy=\"most_frequent\"),    DummyClassifier(strategy=\"stratified\")]\n",
        "logistic_regression = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "svc = SVC(kernel='rbf')\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "results = {}\n",
        "\n",
        "#Train the classifiers and evaluate them on the validation set:\n",
        "for clf in dummy_classifiers + [logistic_regression, svc]:\n",
        "    for vectorizer in [count_vectorizer, tfidf_vectorizer]:\n",
        "        X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "        X_val_transformed = vectorizer.transform(X_val)\n",
        "        clf.fit(X_train_transformed, y_train)\n",
        "        y_pred = clf.predict(X_val_transformed)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        precision_macro = precision_score(y_val, y_pred, average='macro',zero_division=0)\n",
        "        recall_macro = recall_score(y_val, y_pred, average='macro')\n",
        "        f1_macro = f1_score(y_val, y_pred, average='macro')\n",
        "        results[(clf.__class__.__name__, vectorizer.__class__.__name__)] = (accuracy, precision_macro, recall_macro, f1_macro)\n",
        "\n",
        "#Print the evaluation metrics:\n",
        "print(\"Results on Validation Set:\")\n",
        "print(\"{:<25} {:<20} {:<10} {:<10} {:<10}\".format('Classifier', 'Feature Representation', 'Accuracy', 'Precision', 'Recall', 'F1'))\n",
        "for key, value in results.items():\n",
        "    classifier, feature_representation = key\n",
        "    accuracy, precision_macro, recall_macro, f1_macro = value\n",
        "    print(\"{:<25} {:<20} {:.3f}      {:.3f}      {:.3f}     {:.3f}\".format(classifier, feature_representation, accuracy, precision_macro, recall_macro, f1_macro))\n",
        "best_clf = max(results, key=lambda x: results[x][3])\n",
        "best_clf_name = best_clf[0]\n",
        "best_vectorizer_name = best_clf[1]\n",
        "X_train_transformed = vectorizer.fit_transform(rev_train_val)\n",
        "X_val_transformed = vectorizer.transform(rev_val)\n",
        "clf = eval(best_clf_name)()\n",
        "clf.fit(X_train_transformed, rec_train_val)\n",
        "y_pred = clf.predict(X_val_transformed)\n",
        "f1_scores = f1_score(rec_val, y_pred, average=None)\n",
        "classes = clf.classes_\n",
        "plt.bar(classes, f1_scores)\n",
        "plt.title(f\"Macro F1 Scores for {best_clf_name} with {best_vectorizer_name}\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Macro F1 Scores\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "GtMNsP_5nfVO",
        "outputId": "ac5a63fd-e988-43ac-e562-6ed1ee090c1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on Validation Set:\n",
            "Classifier                Feature Representation Accuracy   Precision  Recall    \n",
            "DummyClassifier           CountVectorizer      0.922      0.510      0.511     0.511\n",
            "DummyClassifier           TfidfVectorizer      0.920      0.495      0.495     0.495\n",
            "LogisticRegression        CountVectorizer      0.966      0.799      0.660     0.706\n",
            "LogisticRegression        TfidfVectorizer      0.961      0.480      0.500     0.490\n",
            "SVC                       CountVectorizer      0.965      0.982      0.549     0.581\n",
            "SVC                       TfidfVectorizer      0.966      0.983      0.566     0.607\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression = LogisticRegression(solver='lbfgs', max_iter=1000, C=10)\n",
        "\n",
        "# Define the feature representations\n",
        "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_features=1000)\n",
        "\n",
        "# Evaluate the classifiers using cross-validation\n",
        "for clf in [logistic_regression]:\n",
        "    for vectorizer in  [tfidf_vectorizer]:\n",
        "        X_train_transformed = vectorizer.fit_transform(rev_train)\n",
        "        scores = cross_val_score(clf, X_train_transformed, rec_train, cv=5)\n",
        "        print(f\"{clf.__class__.__name__} with {vectorizer.__class__.__name__}: {scores.mean():.3f} +/- {scores.std():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNErnKcCq2GK",
        "outputId": "48adeb63-019d-41eb-9cc8-f5d0c97302da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression with TfidfVectorizer: 0.958 +/- 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define the pipeline with the vectorizer and classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(solver='lbfgs', max_iter=1000))\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'tfidf__sublinear_tf': [True, False],\n",
        "    'tfidf__max_features': [None, 5000, 10000, 20000],\n",
        "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(rev_val, rec_val)\n",
        "\n",
        "# Print the best parameters and score\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score: {:.3f}\".format(grid_search.best_score_))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG-h7l-Jqa7m",
        "outputId": "232ac69e-9384-4a00-ba5c-feb4a1c25fac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'clf__C': 1000, 'tfidf__max_features': None, 'tfidf__sublinear_tf': False}\n",
            "Best score: 0.964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(rev_train_val, rec_train_val, test_size=0.2, random_state=12)\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Train the classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate the classifier on the validation set\n",
        "y_val_pred = clf.predict(X_val_tfidf)\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "prec = precision_score(y_val, y_val_pred, average='macro',zero_division=0)\n",
        "rec = recall_score(y_val, y_val_pred, average='macro')\n",
        "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Macro-averaged Precision: {prec:.3f}\")\n",
        "print(f\"Macro-averaged Recall: {rec:.3f}\")\n",
        "print(f\"Macro-averaged F1: {f1:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jng6Ib_cne3s",
        "outputId": "dde91a91-307c-4810-b4e4-1397dca9cee6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.961\n",
            "Macro-averaged Precision: 0.480\n",
            "Macro-averaged Recall: 0.500\n",
            "Macro-averaged F1: 0.490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBENVFfdpeiy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EG7ghB7Euue1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-w3nn0E-qENT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Define the ranges of values for each parameter\n",
        "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
        "sublinear_tf_values = [True, False]\n",
        "max_features_values = [None, 1000, 5000, 10000, 50000]\n",
        "# Choose another parameter to tune\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "# Define a function to evaluate the classifier on the validation set with given parameters\n",
        "def evaluate_classifier(c, sublinear_tf, max_features, kernel):\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=sublinear_tf, max_features=max_features)\n",
        "    X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "    X_val_transformed = vectorizer.transform(X_val)\n",
        "    clf = SVC(kernel=kernel, C=c)\n",
        "    clf.fit(X_train_transformed, y_train)\n",
        "    y_pred = clf.predict(X_val_transformed)\n",
        "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
        "    return f1_macro\n",
        "\n",
        "# Loop through all combinations of parameter values and evaluate the classifier\n",
        "best_f1_score = 0\n",
        "for c in c_values:\n",
        "    for sublinear_tf in sublinear_tf_values:\n",
        "        for max_features in max_features_values:\n",
        "            for kernel in kernel_values:\n",
        "                f1_macro = evaluate_classifier(c, sublinear_tf, max_features, kernel)\n",
        "                if f1_macro > best_f1_score:\n",
        "                    best_f1_score = f1_macro\n",
        "                    best_c = c\n",
        "                    best_sublinear_tf = sublinear_tf\n",
        "                    best_max_features = max_features\n",
        "                    best_kernel = kernel\n",
        "\n",
        "# Print the best parameter values and the corresponding f1 score on the validation set\n",
        "print(\"Best parameters:\")\n",
        "print(\"C value:\", best_c)\n",
        "print(\"Sublinear TF:\", best_sublinear_tf)\n",
        "print(\"Max features:\", best_max_features)\n",
        "print(\"Kernel:\", best_kernel)\n",
        "print(\"Best F1 score on validation set:\", best_f1_score)\n",
        "'''\n",
        "\n",
        "\n",
        "#Best parameters:\n",
        "#C value: 10\n",
        "#Sublinear TF: True\n",
        "#Max features: 1000\n",
        "#Kernel: linear\n",
        "#Best F1 score on validation set: 0.7450214164172975"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3DHvqbWuwYb",
        "outputId": "d6b0ed3b-7aef-4f54-ed7d-5566c564023e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:\n",
            "C value: 10\n",
            "Sublinear TF: True\n",
            "Max features: 1000\n",
            "Kernel: linear\n",
            "Best F1 score on validation set: 0.7450214164172975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "UaDda58G6R34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b38542d-cb98-41d3-e2ac-fccd8dbe4598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4ENSbUgHN5J",
        "outputId": "b54b0ad5-2868-4d18-aa3b-48959ae9c31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uH_QuBmJHT33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Encode the text using the tokenizer\n",
        "input_ids = []\n",
        "for doc in data:\n",
        "    encoded = tokenizer.encode(doc['Review'], add_special_tokens=True, truncation=True)\n",
        "    input_ids.append(encoded)\n",
        "\n",
        "# Pad the input sequences\n",
        "max_len = max([len(seq) for seq in input_ids])\n",
        "padded_input_ids = []\n",
        "for seq in input_ids:\n",
        "    padded_seq = seq + [0]*(max_len-len(seq))\n",
        "    padded_input_ids.append(padded_seq)\n",
        "\n",
        "# Convert the input sequences to tensors\n",
        "input_ids = torch.tensor(padded_input_ids)\n",
        "\n",
        "# Extract the first context vector for each document\n",
        "outputs = model(input_ids)\n",
        "context_vectors = outputs.last_hidden_state[:, 0, :].detach().numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB57ggl6HdMd",
        "outputId": "054a4be6-1eda-4e86-fee0-39f98130dffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLj4mwuIHgoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7evtcTmnI5Wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}